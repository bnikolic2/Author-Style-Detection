{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelfile = '''\n",
    "# FROM mistral:7b-instruct-q4_K_M\n",
    "\n",
    "# PARAMETER temperature 0.5\n",
    "\n",
    "# # set the system message\n",
    "# SYSTEM \"\"\"\n",
    "# You are simulating work of a function. You can only response by generating one 0 or one 1. You will be prompted with two paragraphs that are divide by new line symbol. If the paragraphs are written by the same author you generate 0 and if the paragraphs are written by different authors you return 1. \n",
    "# \"\"\"\n",
    "# '''\n",
    "\n",
    "# ollama.create(model='mistral-SCS', modelfile=modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs_df = pd.read_csv('../all_paragraphs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text-id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium-17</td>\n",
       "      <td>Due to the overreach on the initial layoffs, c...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medium-17</td>\n",
       "      <td>I used to be in Pharmacy. Then I did a researc...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medium-17</td>\n",
       "      <td>So if a medical center has any that are partia...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>medium-17</td>\n",
       "      <td>Open vials are supposed to be discarded after ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>medium-17</td>\n",
       "      <td>It costs about 15-35 cents to make a mL of ins...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     text-id                                               text  label  \\\n",
       "0  medium-17  Due to the overreach on the initial layoffs, c...      1   \n",
       "1  medium-17  I used to be in Pharmacy. Then I did a researc...      0   \n",
       "2  medium-17  So if a medical center has any that are partia...      1   \n",
       "3  medium-17  Open vials are supposed to be discarded after ...      1   \n",
       "4  medium-17  It costs about 15-35 cents to make a mL of ins...      1   \n",
       "\n",
       "   version  \n",
       "0        3  \n",
       "1        3  \n",
       "2        3  \n",
       "3        3  \n",
       "4        3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Due to the overreach on the initial layoffs, current Twitter employees are in a pretty empowered position right now. Twitter is sinking and Elon removed the majority of the bilge pumps along with most people who know how to run the boat. He needs every hand on deck and can’t afford to fire people giving 80% and telling him to fuck off from his return to the office edict. Curious to see how many return.\\r\\nI used to be in Pharmacy. Then I did a research project about their markups, especially in the US I was appalled.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs_df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama.generate(model='mistral-SCS', prompt=paragraphs_df['text'][0])['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/171 [17:40<21:18:33, 456.63s/it]"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "\n",
    "for t in tqdm(paragraphs_df['text']):\n",
    "    response_iteration = []\n",
    "    for _ in range(14):\n",
    "        response = ollama.generate(model='mistral-SCS', prompt=t)['response']\n",
    "        response_iteration.append(response)\n",
    "    \n",
    "    responses.append(response_iteration)\n",
    "\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in responses:\n",
    "    for i in range(len(r)):\n",
    "        if(r[i] == '0' or r[i] == '1'):\n",
    "            r[i] = int(r[i])\n",
    "        else:\n",
    "            r[i] = -1\n",
    "\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_minus_one(array):\n",
    "    contains = []\n",
    "    for sub_array in array:\n",
    "        if -1 in sub_array:\n",
    "            contains.append(True)\n",
    "        else:\n",
    "            contains.append(False)\n",
    "    return contains\n",
    "\n",
    "mask = contains_minus_one(responses)\n",
    "for i in range(len(mask)):\n",
    "    if mask[i] == True:\n",
    "        print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
